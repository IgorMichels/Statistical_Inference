{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação - Exemplo 1\n",
    "\n",
    "Neste Notebook iremos simular o Exemplo 1 do 2º Trabalho de Inferência Estatística da FGV - EMAp ministrada pelo professor Luiz Max Carvalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enunciado\n",
    "\n",
    "Suponha que temos duas moedas, Moeda 1 e Moeda 2 de modo que $Pr(\\textit{Cara }|\\textit{ Moeda} = 1) = p_1$ e $Pr(\\textit{Cara }|\\textit{ Moeda} = 2) = p_2$; Suponha que agora façamos o seguinte experimento:\n",
    "  * selecionamos uma moeda aleatoriamente com probabilidade $\\frac{1}{2}$;\n",
    "      \n",
    "  * lançamos a moeda selecionada $m$ vezes;\n",
    "            \n",
    "  * repetimos (i) e (ii) $n$ vezes.\n",
    "        \n",
    "Podemos representar os dados advindos desse experimento como\n",
    "\\begin{equation*}\n",
    "    \\begin{array}{ccccc}\n",
    "        X_{11} & \\dots & X_{1m} & & M_1 \\\\\n",
    "        X_{21} & \\dots & X_{2m} & & M_2 \\\\\n",
    "        \\vdots & \\ddots & \\vdots & & \\vdots \\\\\n",
    "        X_{n1} & \\dots & X_{nm} & & M_n \n",
    "    \\end{array}\n",
    "\\end{equation*}\n",
    "onde $X_{ij}$ é a variável de Bernoulli que representa o resultado do $j$-ésimo lançamento da moeda na $i$-ésima rodada e $M_i \\in \\{1, 2\\}$ é a variável aleatória que guarda a informação sobre qual moeda foi lançada na $i$-ésima rodada do experimento.\n",
    "    \n",
    "Desenvolva um esquema EM para obter o EMV de $\\theta = (p_1, p_2)$ quando desconhecemos os valores de $M_i$, isto é, quando não sabemos que moeda foi escolhida em cada uma das $n$ rodadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos os import's utilizados para realizar a simulação, a definição de $\\theta = (p_1, p_2)$, $n$, $m$ e os lançamentos de moedas, que são os dados que temos em mãos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "p1 = 0.10 # prababilidade de sair cara na moeda 1\n",
    "p2 = 0.70 # prababilidade de sair cara na moeda 2\n",
    "n = 50 # repetições do processo\n",
    "m = 400 # lançamentos de moedas por iteração\n",
    "resultados = np.zeros((n, m))\n",
    "\n",
    "for i in range(n):\n",
    "    if rd.random() < 0.5:\n",
    "        for j in range(m):\n",
    "            if rd.random() < p1:\n",
    "                resultados[i][j] = 1\n",
    "    else:\n",
    "        for j in range(m):\n",
    "            if rd.random() < p2:\n",
    "                resultados[i][j] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso, definimos a função de log-verossimilhança negativa, uma vez que maximizar a função de log-verossimilhança é o mesmo que minimizar tal função, assim, podemos nos valer da função minimize da biblioteca scipy.optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_verossimilhanca_negativa(theta, resultados):\n",
    "    m = len(resultados[0])\n",
    "    n = len(resultados)\n",
    "    soma = 0\n",
    "    for i in range(n):\n",
    "        parcela_M1 = 1\n",
    "        parcela_M2 = 1\n",
    "        for j in range(m):\n",
    "            if resultados[i][j] == 1:\n",
    "                parcela_M1 *= theta[0]\n",
    "                parcela_M2 *= theta[1]\n",
    "            else:\n",
    "                parcela_M1 *= (1 - theta[0])\n",
    "                parcela_M2 *= (1 - theta[1])\n",
    "        parcela = (parcela_M1 + parcela_M2)/2\n",
    "        soma += math.log(parcela)\n",
    "    \n",
    "    return -soma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, definimos o loop do algoritmo EM.\n",
    "\n",
    "Note que o passo E equivale a utilizar $\\theta^{(p)}$ na função definida acima, enquanto o passo M irá, nesse caso, minimizar a função log_verossimilhanca_negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_EM(theta, resultados):\n",
    "    results = minimize(log_verossimilhanca_negativa, theta, args = resultados, bounds = ((0.1, 0.9), (0.1, 0.9)), method = 'SLSQP')\n",
    "    theta = results.x\n",
    "    result_ant = results.fun\n",
    "    diff = result_ant - 0\n",
    "    while diff > 0.000000000001:\n",
    "        results = minimize(log_verossimilhanca_negativa, theta, args = resultados, bounds = ((0.1, 0.9), (0.1, 0.9)), method = 'SLSQP')\n",
    "        theta = results.x\n",
    "        diff = result_ant - results.fun\n",
    "        result_ant = results.fun\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso, podemos utilizar o algoritmo para estimar $\\theta$ a partir de diferentes $\\theta^{(0)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta inicial: [0.3, 0.9]\n",
      "Theta final: [0.10349999 0.6984    ]\n",
      "Função log-verossimilhança negativa: 9483.855228185645\n",
      "\n",
      "Theta inicial: [0.5, 0.5]\n",
      "Theta final: [0.40095055 0.40095055]\n",
      "Função log-verossimilhança negativa: 13467.899582980837\n",
      "\n",
      "Theta inicial: [0.1, 0.7]\n",
      "Theta final: [0.10349999 0.69839999]\n",
      "Função log-verossimilhança negativa: 9483.855228185643\n",
      "\n",
      "Theta usado para gerar os dados: [0.1, 0.7]\n",
      "Função log-verossimilhança negativa: 9484.589739464376\n"
     ]
    }
   ],
   "source": [
    "theta = [0.3, 0.9]\n",
    "print('Theta inicial:', theta)\n",
    "results = loop_EM(theta, resultados)\n",
    "\n",
    "print('Theta final:', results.x)\n",
    "print('Função log-verossimilhança negativa:', results.fun)\n",
    "print()\n",
    "\n",
    "theta = [0.5, 0.5]\n",
    "print('Theta inicial:', theta)\n",
    "results = loop_EM(theta, resultados)\n",
    "\n",
    "print('Theta final:', results.x)\n",
    "print('Função log-verossimilhança negativa:', results.fun)\n",
    "print()\n",
    "\n",
    "theta = [0.1, 0.7]\n",
    "print('Theta inicial:', theta)\n",
    "results = loop_EM(theta, resultados)\n",
    "\n",
    "print('Theta final:', results.x)\n",
    "print('Função log-verossimilhança negativa:', results.fun)\n",
    "print()\n",
    "\n",
    "print('Theta usado para gerar os dados:', [p1, p2])\n",
    "print('Função log-verossimilhança negativa:', log_verossimilhanca_negativa([p1, p2], resultados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que com $\\theta^{(0)} = (0.5, 0.5)$ o $\\theta$ final não chegou próximo ao $\\hat{\\theta}$, o que nos mostra que nem sempre o Algoritmo EM vai para o ponto excelente, mas note que ele ele tende a um ponto de excelência local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [0.5, 0.5]\n",
      "Função log-verossimilhança negativa: 13862.9436111989\n",
      "\n",
      "Theta: [0.41, 0.41]\n",
      "Função log-verossimilhança negativa: 13471.293201425553\n",
      "\n",
      "Theta: [0.39, 0.39]\n",
      "Função log-verossimilhança negativa: 13472.923112787748\n"
     ]
    }
   ],
   "source": [
    "print('Theta:', [0.5, 0.5])\n",
    "print('Função log-verossimilhança negativa:', log_verossimilhanca_negativa([0.5, 0.5], resultados))\n",
    "print()\n",
    "print('Theta:', [0.41, 0.41])\n",
    "print('Função log-verossimilhança negativa:', log_verossimilhanca_negativa([0.41, 0.41], resultados))\n",
    "print()\n",
    "print('Theta:', [0.39, 0.39])\n",
    "print('Função log-verossimilhança negativa:', log_verossimilhanca_negativa([0.39, 0.39], resultados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o valor final de $\\theta$ quando $\\theta^{(0)} = (0.5, 0.5)$ ainda minimizou a a função de log-verossimilhança negativa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
